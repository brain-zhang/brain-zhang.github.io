<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Tools | Living a Simple Life is a Happy Life]]></title>
  <link href="http://happy123.me/blog/categories/tools/atom.xml" rel="self"/>
  <link href="http://happy123.me/"/>
  <updated>2018-07-27T14:09:00+08:00</updated>
  <id>http://happy123.me/</id>
  <author>
    <name><![CDATA[memoryboxes]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Migrate Vm Instances and Snapshots From Different Vps Supporters or Accounts]]></title>
    <link href="http://happy123.me/blog/2018/07/21/migrate-vm-instances-and-snapshots-from-different-vps-supporters-or-accounts/"/>
    <updated>2018-07-21T09:11:55+08:00</updated>
    <id>http://happy123.me/blog/2018/07/21/migrate-vm-instances-and-snapshots-from-different-vps-supporters-or-accounts</id>
    <content type="html"><![CDATA[<p>虽然已经进入X时代了，但电脑城装机习惯性还是用Ghost，无他，习惯方便。</p>

<p>Linux上面系统迁移，网上搜一搜，大批文章还是原始的dd, rsync之类；当然，不是说他不行，而是面向小白实在是有点坑啊。</p>

<p>云时代，不同厂商间基本都提供了<code>快照</code>+<code>在线热迁移</code>的方案了，用起来也很舒服。</p>

<p>那么，作为一个VPS小白用户，怎么在不同的账号，或者说不同的厂商之间，迁移我的Linux系统呢？</p>

<p>比如我在vultr上面有两个账号，vultr的快照功能是很赞的，免费、速度快、生成虚机靠谱；</p>

<p>那么问题来了，怎么把账号A的Linux A迁移到账号B的Linux B虚机上呢？</p>

<p>官方回复是还没有考虑这个功能，然后Linux怎么可能做不到这种简单的事情呢？当然立刻就有人回复了详细的搞法，还贴心的附录了视频:</p>

<p><a href="https://discuss.vultr.com/discussion/104/snapshot-image-downloads/p2">https://discuss.vultr.com/discussion/104/snapshot-image-downloads/p2</a></p>

<!-- more -->


<h4>我们也嘴炮一下整个过程:</h4>

<ol>
<li><p>对Linux A建立SnapShot A</p></li>
<li><p>从SnapShot A创立一台虚机 (注意这台虚机的磁盘要比Linux A的磁盘大，比如Linux A是5$的套餐15GB，那么最好建立一个20$的套餐45GB)</p></li>
<li><p>vultr 有挂载光盘的功能，可以挂载一个linux live CD,用这张Live CD启动新虚机</p></li>
<li><p>dd 命令完全拷贝原有磁盘</p>

<p> dd if=/dev/vtbd0 bs=1m | gzip -c | ssh -e none myolduser@myoldserverip &lsquo;cat > backupsnapshot.iso.gz&rsquo;</p></li>
<li><p>账号B开一台虚机，把backupsnapshot.iso.gz拷贝过去</p></li>
<li><p>同样挂载Live CD，反向dd，恢复文件系统</p></li>
<li><p>重启，改配置，赋权限，搞定</p></li>
</ol>


<p>说是嘴炮，是因为我之前硬盘dd对拷过，对于速度和之后的配置兼容深为烦恼，更不用说KVM上面用这个招数去做迁移了，我一个坑都不想踩的。</p>

<p>光是看看上面一波操作，我就没兴趣折腾了。当然也有很多人的乐趣就是折腾，但是年纪大了就老是想偷懒。</p>

<p>之前在不同物理机之间做Linux迁移，用clonezilla居多，虽然有一些Raid方面的支持会有问题，总体来说我对它的稳定性和便利性有巨大信任，但从来没有在KVM上搞过，这次我完整实验了一把，效果MAX。</p>

<h4>下面我们说说怎么用clonezilla把上面繁琐的手工操作搞得不那么痛苦一点:</h4>

<ol>
<li><p>先去clonezilla.org 官网，找到下载地址，好吧，我已经帮你找好了:</p>

<p> <a href="http://onet.dl.osdn.jp/clonezilla/69273/clonezilla-live-2.5.5-38-amd64.iso">http://onet.dl.osdn.jp/clonezilla/69273/clonezilla-live-2.5.5-38-amd64.iso</a></p></li>
<li><p>vultr很贴心的提供了从url上传镜像的功能，我们到下面这个功能项中把iso镜像的url填进去，添加clonezilla镜像文件到vultr:</p>

<p> <a href="https://my.vultr.com/iso/add/">https://my.vultr.com/iso/add/</a></p></li>
<li><p>点开虚机Linux A，点击<code>Settings</code> &ndash;> <code>Custom ISO</code> &ndash;> 选择clonezilla &ndash;> 点击 <code>Attach ISO and Reboot</code></p></li>
<li><p>用VNC连接虚机，进入clonezilla的界面</p></li>
<li><p>进入菜单项，<code>第一菜单800X600分辨率</code> &ndash;> <code>简体中文</code> &ndash;> <code>使用再生龙</code></p></li>
<li><p>选择 <code>remote-source 进入远程设备克隆的源端</code></p></li>
<li><p>选择 <code>初学模式：接受默认的选择</code></p></li>
<li><p>选择 <code>复制本机硬盘到它机硬盘</code></p></li>
<li><p>选择 <code>设定固定IP地址</code></p></li>
<li><p>设定IP,子网掩码，网关,域名服务器，如果机器有多块网卡的话，一般会列出网卡名字和MAC地址供你选择，vultr一般是双网卡(如果你启用了内网地址的话),网络信息在vultr的主机settings中能查到。</p></li>
<li><p>选择要克隆的硬盘，设定没有问题的话，下面一路YES下去，机器就会进入等待目标端连接的状态</p></li>
<li><p>在账号B的Linux B中重复1-11步操作，不同的是第6步选择目标端，第8步选择 <code>从镜像文件恢复至本机硬盘</code>, 之后填入Linux A的IP地址，就可以开始克隆对拷了</p></li>
<li><p>我在不同vultr的账号中测试了Ubuntu16.04, Centos7.1, FreeBSD 10的迁移，效果MAX</p></li>
</ol>


<p>看起来步骤不少，熟练了还是能迅速操作的，clonezilla赞一个</p>

<h4>一点小ToolTIps:</h4>

<ul>
<li><p>这个方法其实可以适用所有KVM虚机迁移，所以只要服务商开了自定义镜像挂载的功能，都可以跨公网对拷</p></li>
<li><p>如果A和B不能直接通信的话，可以开一台中转机器C，在Linux A的一端把硬盘 clone为镜像文件，通过SSH文件服务器的方式转存到C上，然后在B上连接SSH文件服务器C，从而还原系统; 提示一下，其实生成的镜像文件挺小的，比dd之后压缩还小的多</p></li>
<li><p>如果clone的时候报错，一般是A 端的文件系统有损坏，这个时候可以简单的执行 <code>shutdown -rF now</code> ,重启后自动修复一把，之后再挂载clonezilla ISO进行克隆</p></li>
</ul>


<h4>最后，让我们期望所有的服务商都能提供 qcow2 的导入导出功能</h4>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Grep Obtain Patterns From File]]></title>
    <link href="http://happy123.me/blog/2018/07/04/how-to-grep-obtain-patterns-from-file/"/>
    <updated>2018-07-04T18:06:55+08:00</updated>
    <id>http://happy123.me/blog/2018/07/04/how-to-grep-obtain-patterns-from-file</id>
    <content type="html"><![CDATA[<p>有一个100G的大文本文件 emailinfo.dict，包含邮箱及用户昵称; 格式为</p>

<p><code>
hello@163.com,你是我的海
...
</code></p>

<p>有一个用户名文件user.txt，格式为:</p>

<p><code>
aaa
xxxx
....
</code></p>

<p>我们希望找出emailinfo.dict中，以user.txt中用户名开头的所有内容。</p>

<p>首先将user.txt内容改为:</p>

<p><code>
^aaa
^xxxx
....
</code></p>

<p>然后执行:</p>

<pre><code>grep -G -f user.txt emailinfo.dict
</code></pre>

<p>这个<code>-G</code>参数又花了我半个小时去读文档，我都不知道第几次做这种事情了。人年纪大了果然只能靠笔记。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Set Proxy for Git]]></title>
    <link href="http://happy123.me/blog/2018/06/11/how-to-set-proxy-for-git/"/>
    <updated>2018-06-11T11:12:20+08:00</updated>
    <id>http://happy123.me/blog/2018/06/11/how-to-set-proxy-for-git</id>
    <content type="html"><![CDATA[<h3>全局设置和取消:</h3>

<p>```
git config &mdash;global https.proxy <a href="http://127.0.0.1:1080">http://127.0.0.1:1080</a></p>

<p>git config &mdash;global https.proxy <a href="https://127.0.0.1:1080">https://127.0.0.1:1080</a></p>

<p>git config &mdash;global &mdash;unset http.proxy</p>

<p>git config &mdash;global &mdash;unset https.proxy
```</p>

<h3>local设置和取消:</h3>

<p>```
git config  https.proxy <a href="http://127.0.0.1:1080">http://127.0.0.1:1080</a></p>

<p>git config  https.proxy <a href="https://127.0.0.1:1080">https://127.0.0.1:1080</a></p>

<p>git config  &mdash;unset http.proxy</p>

<p>git config  &mdash;unset https.proxy
```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Split Large ‘tar’ Archive Into Multiple Files of Certain Size]]></title>
    <link href="http://happy123.me/blog/2018/06/10/how-to-split-large-tar-archive-into-multiple-files-of-certain-size/"/>
    <updated>2018-06-10T21:50:43+08:00</updated>
    <id>http://happy123.me/blog/2018/06/10/how-to-split-large-tar-archive-into-multiple-files-of-certain-size</id>
    <content type="html"><![CDATA[<p>有时候需要压缩文件的时候同时分割一下:</p>

<p><code>
tar czvf - -C /mnt/g/dict/ weakpass_merge.dict |split -b 10000M - "weakpass.part.tar.gz."
</code></p>

<p>还原:</p>

<p><code>
cat weakpass.part.tar.gz.*|tar zxvf
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Improve Performance Your Cmd by Parallel]]></title>
    <link href="http://happy123.me/blog/2018/05/06/how-to-improve-performance-your-cmd-by-parallel/"/>
    <updated>2018-05-06T09:32:03+08:00</updated>
    <id>http://happy123.me/blog/2018/05/06/how-to-improve-performance-your-cmd-by-parallel</id>
    <content type="html"><![CDATA[<p>有很多时候，处理一个大文件，常规命令并不能很好的利用多核</p>

<!-- more -->


<p>例如，一个1T的文本，百亿条数据，我想要:</p>

<p><code>
wc -l test.txt
</code></p>

<p>或者</p>

<p><code>
fgrep xxxx test.txt
</code></p>

<p>一般机器就会自觉进入<code>一核有难，其它核点赞</code>的看戏模式。</p>

<p>我花钱配了这么多核，加了这么多内存，不是让大家来看戏的。于是祭出<code>parallel</code>~</p>

<h2>原理</h2>

<p>parallel 是一个perl脚本，通过分割输入，并行处理的方式来加速执行命令。</p>

<p>例如:</p>

<p><code>
wc -l test.txt
</code></p>

<p>简单想想就是用个for循环split文件，挨个wc，然后相加。parallel就是自动帮你把这类事情做掉而已。大道不过两三行，所谓外部排序，Map-Reduce莫不如是。</p>

<h2>安装 (ubuntu 16.04LTS)</h2>

<p><code>
 apt-get install parallel
</code></p>

<h2>示例</h2>

<h4>最快的办法计算一个大文件的行数</h4>

<p><code>
cat bigfile.txt | parallel --no-notice --pipe wc -l | awk '{s+=$1} END {print s}'
</code></p>

<p>非常的巧妙，先使用parallel命令‘mapping’出大量的wc -l调用，形成子计算，最后通过管道发送给awk进行汇总</p>

<h4>SED, 想在一个巨大的文件里使用sed命令做大量的替换操作吗？</h4>

<p>常规做法：
<code>
sed s^old^new^g bigfile.txt
</code></p>

<p>现在你可以：
<code>
cat bigfile.txt | parallel --no-notice --pipe sed s^old^new^g
</code></p>

<h4>GREP 一个非常大的文本文件</h4>

<p>以前你可能会这样：</p>

<p><code>
grep pattern bigfile.txt
</code></p>

<p>现在你可以这样：
<code>
cat bigfile.txt | parallel --no-notice --pipe grep 'pattern'
</code></p>

<p>或者这样：
<code>
cat bigfile.txt | parallel --no-notice --block 10M --pipe grep 'pattern'
</code></p>

<p>这第二种用法使用了 –block 10M参数，这是说每个内核处理1千万行——你可以用这个参数来调整每个CUP内核处理多少行数据。</p>

<h4>压缩一个非常大的文件</h4>

<p>bzip2是比gzip更好的压缩工具，但它很慢！别折腾了，我们有办法解决这问题。</p>

<p>以前的做法：
<code>
cat bigfile.bin | bzip2 --best &gt; compressedfile.bz2
</code></p>

<p>现在这样：
<code>
cat bigfile.bin | parallel --no-notice --pipe --recend '' -k bzip2 --best &gt; compressedfile.bz2
</code></p>

<h2>扩展</h2>

<p>作为一个Python党，经常写一些<code>用过即弃</code>的边角料脚本</p>

<p>比如最近要把一个1T的文件汉字全部转换为拼音，初版当然是这样的:</p>

<h4>版本1</h4>

<p>```
with io.open(sys.argv[1], encoding=&lsquo;utf-8&rsquo;) as fp:</p>

<pre><code>for line in fp:
    print(lazy_pinyin(line))
</code></pre>

<p>```</p>

<p>lazy_pinyin的效率奇慢无比，这回陷入了一核有难，其它核+内存+磁盘全部看戏模式</p>

<p>作为一个初级合格的Python开发人员，你当然说要用process，于是我们有了第二版:</p>

<h4>版本2</h4>

<p>```
from multiprocessing import Pool
pool = Pool(16)
with io.open(sys.argv[1], encoding=&lsquo;utf-8&rsquo;) as fp:</p>

<pre><code>pool.map(lazy_pinyin, fp, 16)
pool.close()
pool.join()
</code></pre>

<p>```</p>

<p>嗯，很好，16个核都跑起来了；但是你有很快尴尬的发现，map把文件一把load进来，内存有难了</p>

<h4>~~~~</h4>

<p>作为一个初级合格的Python开发人员，你当然说不要一把读进来，要用chunk_read，一次读一块，或者更高级一点，直接用mmap映射进内存巴拉巴拉</p>

<h4>少年，这还是那个边角料脚本吗，你已经在它上面操心一个小时了，还能不能愉快的玩耍了</h4>

<p>让 parallel来拯救你</p>

<h4>版本3</h4>

<p>```
import fileinput</p>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>for line in fileinput.input():
    lazy_pinyin(line)
</code></pre>

<p>```</p>

<p>然后执行:</p>

<p><code>
cat bigfile.txt| parallel --no-notice --pipe python pinyinconv.py &gt; pinyin.result
</code></p>

<p>享受所有CPU满负荷运载的工头压榨工人的快感吧</p>

<h2>一些扩展</h2>

<ul>
<li>为啥所有的parallel都带有一个奇怪的&mdash;no-notice?</li>
</ul>


<p>嗯，虽然这个作者非常非常好，但是他总是在命令前面输出一些捐助提示；当然我并不是讨厌这种做法，但看多了总有些疲劳，你懂的~~</p>

<ul>
<li>我有一些参数想传给程序，怎么办？</li>
</ul>


<p><code>
 seq 3|parallel --no-notice -q echo seq{}
</code></p>

<ul>
<li>这个命令很好，但是语法好像啰嗦了一些，还有其它的替代命令吗？</li>
</ul>


<p>嗯~ o(<em>￣▽￣</em>)o，还是有的，xargs有个-n参数，类似的效果，不过功能弱化很多，基本上是鸡肋</p>

<h2>参考:</h2>

<h4>手册:</h4>

<p><a href="https://www.gnu.org/software/parallel/parallel_tutorial.html">https://www.gnu.org/software/parallel/parallel_tutorial.html</a></p>

<h4>资料:</h4>

<p><a href="http://www.freeoa.net/osuport/sysadmin/use-gnu-parallel-multi-core-speed-up-cmd_2343.html">http://www.freeoa.net/osuport/sysadmin/use-gnu-parallel-multi-core-speed-up-cmd_2343.html</a></p>

<p>我的博客即将搬运同步至腾讯云+社区，邀请大家一同入驻：<a href="https://cloud.tencent.com/developer/support-plan?invite_code=1bnzu1pmog27t">https://cloud.tencent.com/developer/support-plan?invite_code=1bnzu1pmog27t</a></p>
]]></content>
  </entry>
  
</feed>
